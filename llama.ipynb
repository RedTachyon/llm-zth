{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57677b06af97783d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:27:14.931961Z",
     "start_time": "2024-01-31T09:27:13.937851Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from smollama import Llama, LLaMAConfig, generate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:27:14.935743Z",
     "start_time": "2024-01-31T09:27:14.932685Z"
    }
   },
   "id": "3d9b98092bbec3da",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "eos_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({'pad_token': eos_token})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:27:15.186972Z",
     "start_time": "2024-01-31T09:27:14.935145Z"
    }
   },
   "id": "5b6a61f0e44a4a5a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([29871])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:28:34.063978Z",
     "start_time": "2024-01-31T09:28:34.061643Z"
    }
   },
   "id": "bd1f5c1bf375df0b",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [1, 3118, 2462], 'attention_mask': [1, 1, 1]}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<s>One day\", add_special_tokens=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:28:37.399967Z",
     "start_time": "2024-01-31T09:28:37.396770Z"
    }
   },
   "id": "3193fb14c428e835",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariel/projects/llm-zth/.venv/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\")\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-30T23:31:56.681556Z",
     "start_time": "2024-01-30T23:31:53.325906Z"
    }
   },
   "id": "initial_id",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2119719 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5a56af49ea44e88a1bdba1d363b38a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtokenize_function\u001B[39m(examples):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer(examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m], add_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 4\u001B[0m tokenized_datasets \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenize_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Set the format to PyTorch tensors, but don't include padding yet\u001B[39;00m\n\u001B[1;32m      7\u001B[0m tokenized_datasets\u001B[38;5;241m.\u001B[39mset_format(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m], device\u001B[38;5;241m=\u001B[39mDEVICE)\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/dataset_dict.py:868\u001B[0m, in \u001B[0;36mDatasetDict.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001B[0m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    866\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[0;32m--> 868\u001B[0m     \u001B[43m{\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m    890\u001B[0m )\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/dataset_dict.py:869\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    866\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[1;32m    868\u001B[0m     {\n\u001B[0;32m--> 869\u001B[0m         k: \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    888\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    889\u001B[0m     }\n\u001B[1;32m    890\u001B[0m )\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:592\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    590\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    591\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 592\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    593\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:557\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    550\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    551\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[1;32m    555\u001B[0m }\n\u001B[1;32m    556\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 557\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    558\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3093\u001B[0m, in \u001B[0;36mDataset.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[1;32m   3087\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3088\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[1;32m   3089\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3090\u001B[0m         total\u001B[38;5;241m=\u001B[39mpbar_total,\n\u001B[1;32m   3091\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3092\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m-> 3093\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_single\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   3094\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   3095\u001B[0m \u001B[43m                \u001B[49m\u001B[43mshards_done\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3470\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[1;32m   3466\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m   3467\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[1;32m   3468\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[1;32m   3469\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3470\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3473\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3474\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3475\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3476\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[1;32m   3477\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[1;32m   3478\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3479\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3349\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[1;32m   3347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[1;32m   3348\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[0;32m-> 3349\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[1;32m   3351\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   3352\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[1;32m   3353\u001B[0m     }\n",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m, in \u001B[0;36mtokenize_function\u001B[0;34m(examples)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtokenize_function\u001B[39m(examples):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2803\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2801\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[1;32m   2802\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[0;32m-> 2803\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2804\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2805\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2889\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2884\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2885\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch length of `text`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match batch length of `text_pair`:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2886\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text_pair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2887\u001B[0m         )\n\u001B[1;32m   2888\u001B[0m     batch_text_or_text_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(text, text_pair)) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m text\n\u001B[0;32m-> 2889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2891\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2895\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2896\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2897\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2898\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2899\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2900\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2901\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2902\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2903\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2905\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2906\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2907\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2908\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2909\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[1;32m   2910\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   2911\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2927\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2928\u001B[0m     )\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3080\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   3070\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[1;32m   3071\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[1;32m   3072\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   3073\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3077\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3078\u001B[0m )\n\u001B[0;32m-> 3080\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3082\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3087\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3088\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3089\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3090\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3091\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3092\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3093\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3094\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3095\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3096\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3097\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3098\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:504\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001B[39;00m\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_truncation_and_padding(\n\u001B[1;32m    497\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m    498\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    501\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m    502\u001B[0m )\n\u001B[0;32m--> 504\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_pretokenized\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[1;32m    516\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    517\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[1;32m    518\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[1;32m    528\u001B[0m ]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], add_special_tokens=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Set the format to PyTorch tensors, but don't include padding yet\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\"], device=DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a data collator that will dynamically pad the batches\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T23:35:56.207433Z",
     "start_time": "2024-01-30T23:35:49.534253Z"
    }
   },
   "id": "f351cc8631dfde37",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorWithPadding(tokenizer)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    return_tensors=\"pt\",\n",
    "    mlm=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T23:32:00.256521Z",
     "start_time": "2024-01-30T23:32:00.254647Z"
    }
   },
   "id": "9b269c558a17e066",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset[\"train\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T23:32:31.559011Z",
     "start_time": "2024-01-30T23:32:31.556819Z"
    }
   },
   "id": "e7b7f6cd46f15286",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'text': ['Once upon a time, there was a little girl named Lily. She loved to ride her bike with her friends. One day, Lily and her friends were riding their bikes to the park. Lily\\'s friend, Emily, had a new bike with pedals that were hard to push. \\n\\nEmily said, \"I can\\'t ride my bike very fast. My pedals are too hard to push.\" \\n\\nLily suggested, \"Maybe we can help you pedal faster. You can ride with us and we can all have fun together!\" \\n\\nEmily smiled and felt less shy. She was happy to ride with her friends and they all had a great time at the park. From that day on, they always helped each other when they needed it. The end.',\n  'Once upon a time, there was a little girl named Sally. Sally had the most beautiful eyes and ever since she was born she always had a big smile on her face. One day Sally noticed something strange; it was dark outside and there was no moon in sight. She looked around and wondered what had happened.\\n\\nJust then, Sally heard a voice. It was her father. He said, \"Sally, I think all the stars have moved away and it\\'s so dark, but do not be afraid, I\\'m here with you\". Sally felt confident and safe.\\n\\nSuddenly, Sally noticed a tiny point of light outside their window. She moved closer and saw that her father had lit a small candle to guide her through the night. He smiled and said, \"There\\'s nothing to worry about. The candle will guide you even when it\\'s dark and cold outside.\\n\\nThe next morning, Sally looked outside and noticed that the trees and ground were iced with snow. Just then, it hit her: she had felt safe and warm because she knew that someone was watching over her. And it doesn\\'t matter if it\\'s night or day, a candle and a loving heart can warm the coldest winters.\\n\\nThe moral of the story is to never be afraid of the dark; when you need love and guidance, remember that a candle will always light the way.',\n  \"Once upon a time, in a peaceful town, there was a little girl named Olive. Olive loved to laugh and play with her friends. She was always happy and everyone loved her.\\n\\nOne day, Olive and her friends were playing by a big tree. They were laughing and having lots of fun. The sun was shining and the birds were singing. It was a beautiful day.\\n\\nBut then, a big storm came. The wind blew very hard and the rain started to fall. Olive and her friends were scared. They tried to run home, but the wind was too strong. Olive got lost and couldn't find her way back.\\n\\nOlive was very sad and scared. She cried and cried, but no one could hear her. The storm got worse and Olive was all alone. She couldn't laugh anymore.\\n\\nIn the end, Olive never found her way back home. Her friends and family missed her very much. The peaceful town was never the same without Olive's laugh.\",\n  'Once upon a time there was a small girl called Anna. She loved to run around the garden and play with her toys. One day, Anna saw something shiny in the grass. She ran to pick it up - it was a perfect diary.\\n\\n\"Oh wow, this diary is so nice!\" said Anna.\\n\\nAnna put the diary in her pocket and ran inside to show her mother her new toy.\\n\\n\"Look mum, I found a perfect diary!\" Anna said.\\n\\nMum smiled at Anna and said \"That\\'s great! You can keep it and fill it with wonderful things\".\\n\\nSo Anna ran back outside to the garden with her new diary and sat down to draw and write. She was so happy and it was a perfect day for writing.',\n  \"Annie and Tom were married. Tom always wanted Annie to dress in the same way. He wanted her to look like all the other married ladies.\\n\\nAnnie didn't like it, but she did it anyway because she wanted to make Tom happy. But no matter how much she tried, it didn't work. Nothing she did seemed useful. She was still not like the others.\\n\\nOne day, Tom decided he had had enough. He told Annie to leave, and she had to go away. Annie felt very sad but she knew she couldn't do anything about it. And that was the end of their marriage.\",\n  'Once upon a time, there was a little boy named Timmy. Timmy loved to play with his toy cars and trucks. One day, Timmy\\'s friend Billy came over to play with him. Timmy was so excited to show Billy his new truck, but when Billy tried to play with it, he accidentally broke it.\\n\\nTimmy was very sad and angry. He pointed at Billy and said, \"You broke my truck!\" But then Timmy remembered what his mom had told him about forgiving. He took a deep breath and said to Billy, \"I forgive you for breaking my truck.\"\\n\\nBilly was very happy that Timmy forgave him. He said, \"Thank you, Timmy. I\\'m sorry I broke your truck.\" Timmy smiled and said, \"It\\'s okay, Billy. Let\\'s play with my other toys instead. Maybe we can find one that fits both of us.\" And they had a great time playing together. The end.',\n  'Once there were two best friends, Mike and Jane. They were always outside playing. Today they had found a magical box in the park. When they opened it,Mike said, \"Oh wow!\" \\n\\nInside the box were lots of plastic toys. They were very popular and each one was brightly coloured.\\n\\n\"What should I pick?\", Mike asked Jane.\\n\\n\"I will offer you the yellow car!\", Jane said.\\n\\nMike really liked the yellow car and he was very happy.\\n\\n\"Thank you Jane!\", Mike said.\\n\\nThey both held onto the car and started to play. It was the best day ever!',\n  'Once upon a time, a man wanted to design something fun. He got tire and tried to think of what to make with them. He thought about it for a long time and then he had an idea! He used the tire and designed a big blue slide. \\n\\nThe man was so proud of his work. He brought other people over to try out the slide. Everyone had so much fun and wanted to go down the slide again and again. \\n\\nOne day, a little 3-year-old girl came to visit the slide. She was so excited and ran up the steps of the blue slide. She giggled and laughed as she rode down the slide. She said it was the best slide she ever tried and thanked the man for his amazing design. \\n\\nThe man smiled with joy and was happy to see how much the little girl enjoyed the slide. From that day on, the blue slide became known around the world as the most fun slide to slide down.',\n  'Once upon a time, there was a small dictionary. The dictionary was very curious and always wanted to learn new things. One day, the dictionary decided it wanted to change and learn new words. So it flew off and began exploring the world looking for new words to learn.\\n\\nThe dictionary had so many new adventures. It visited different countries, met new people, and saw lots of different things. Everywhere the dictionary went, it learned new words.\\n\\nFinally the dictionary flew back home. It was so excited to share all the new words it had learned and to show off how different it had become. The small dictionary was very proud of all the changes it had made.',\n  \"Once upon a time, there was a little boy named Timmy. He loved to watch airplanes fly high in the sky. One day, Timmy went to the airport with his mommy and daddy. They saw a pilot getting ready to fly a big airplane. Timmy was so excited to watch the pilot take off into the high sky. The airplane was so big and loud, Timmy's ears tickled. He waved to the pilot as the airplane flew higher and higher. Timmy couldn't wait to watch more planes fly high in the sky.\",\n  \"John was feeling restless one day, so he decided to go for a walk. He brought his pan with him, as it had been given to him by his uncle which was very special to him.\\n\\nAs he was walking along, he noticed something in the distance. It was a big, open field, and it was filled with tall grass. The sun was shining and a warm breeze was blowing. He was so excited and he decided to walk over and explore.\\n\\nJohn entered the field and saw something in the middle. He couldn't believe his eyes, it was a big rock. John was thrilled and he ran over to it. He saw some marks on the rock and he wondered why someone would have done it.\\n\\nSuddenly, John had an idea. He scooped up some dirt with his pan and started marking the rock. He stirred and mixed the dirt and made patterns until he was happy with it. He was so pleased and proud that he'd marked the rock.\\n\\nAs he and his pan were walking back, John noticed something different in the field. He realized that the marks on the rock had formed a path that lead from the open field and into the woods. He smiled, knowing he'd found something special that day.\",\n  'Ben and Lily were twins who liked to play together. One day, they saw a big steak on the table. It smelled good and looked yummy. They wanted to eat some, but their mom said no. She said the steak was for dinner and they had to wait.\\n\\nBen was not happy. He was hungry and curious. He said to Lily, \"I dare you to take a bite of the steak. I bet you are too scared.\" Lily was not scared. She was brave and smart. She said, \"No, Ben. That is not nice. Mom will be angry if we touch the steak. We have to listen to her.\"\\n\\nBen did not listen. He was naughty and sneaky. He said, \"Fine, I will do it. Watch me.\" He tiptoed to the table and reached for the steak. He was about to bite it when he heard a loud bark. It was Rex, their dog. Rex saw the steak too and wanted it. He jumped on the table and grabbed the steak in his mouth. He ran away with it, wagging his tail.\\n\\nBen and Lily were shocked. They did not know what to do. They heard their mom coming. They were afraid she would be mad. They ran to their room and hid under the bed. They hoped Rex would not come back.\\n\\nTheir mom saw the mess on the table. She saw the steak was gone. She saw Rex\\'s paw prints on the floor. She knew what happened. She was not mad. She was generous and kind. She said, \"Oh, Rex. You are a naughty dog. But I love you anyway. I guess we will have something else for dinner.\" She smiled and gave Rex a hug. She went to the kitchen and made some soup and sandwiches. She called Ben and Lily to come and eat. She said, \"I know you were tempted by the steak, but you did the right thing. You are good kids. I love you too.\" She gave them a hug and a kiss. They said, \"We love you, mom. We are sorry, mom.\" They ate their soup and sandwiches and shared some with Rex. They were happy and grateful. They learned their lesson. They never dared to touch the steak again.',\n  'Once upon a time there was a little girl named Mary. Mary loved to dress up in her long uniform each day. Her uniform reminded her of a big adventure she had taken the summer before.\\n\\nOne day, Mary asked her mom, â€œMom, why do I have to wear this uniform?â€ Her mom smiled and said, â€œMy darling, I want you to remember that itâ€™s important to always do your best. No matter what youâ€™re doing, you should always try your hardest and be your best self.â€\\n\\nMary thought about this for a moment, then smiled. From then on, she remembered her momâ€™s words of wisdom every time she got dressed in her long uniform. She was reminded to always try her best, no matter what she did.\\n\\nThe moral of this story is that it is important to always do your best and be your best self. Remember this, little ones!',\n  'Once upon a time there was a little boy called Tommy. Tommy wanted to do something special so he decided to go outside and pray. He knelt down in the grass and he closed his eyes. He felt the warm sunshine on his face and the wind through his hair. \\n\\nTommy opened his eyes and noticed something strange. There was a shadow hovering over him! He looked in the direction of the shadow and saw a tall man wearing a cloak. \\n\\nThe man kneeled down to Tommy\\'s height. \"What were you doing?\" he asked.\\n\\nTommy replied, \"I was praying.\"\\n\\nThe man laughed and said, \"You must be ready to receive an answer. I want to help you.\" \\n\\nTommy was scared but he said something brave. \"Yes please, I\\'m ready.\"\\n\\nThe man took a deep breath and closed his eyes. He waved his hands in the air and soon the shadow disappeared. \\n\\nTommy smiled, he knew it was his answer. From then on, whenever he needed help or courage, he prayed under the warm sunshine.',\n  'It was a gloomy day. The sky was grey and the trees were still. Suddenly, everyone heard a strange noise. It was snow! The snow had started falling from the sky. All the children put on their warm jackets and hats and ran outside to see.\\n\\nThey looked up and saw the snowflakes falling down. They laughed and spun around, trying to catch them. It felt magical! Suddenly, the children heard a funny noise. They stopped and listened carefully. It was two birds chirping, singing a sweet song.\\n\\nThe children felt very happy. They hugged each other and watched the snowflakes falling. Even though it was gloomy, it was still a special day. They looked up one last time and smiled, before running back inside to drink some hot chocolate.',\n  'Once upon a time there was a group of friends. They all liked playing together and had lots of fun. On day, they went for walk in the park. When they arrived, they all admired the flowers. Suddenly, a bird flew down. It was very angry! It shouted out loud. One of the friends was scared and started to cry. \\n\\nThe other friends comforted him, but the bird was still angry. Then, one of the kids had an idea. He said, \"Let\\'s all make silly faces at the bird. We can show it that we are not scared!\" \\n\\nThe group of friends followed the boy\\'s suggestion and smiled and winked at the bird. Suddenly, the bird stopped being angry. It hopped around them and even made some funny noises. The friends all laughed and admired each otherâ€™s funny faces. \\n\\nThe bird flew away and the friends continued to admire the flowers in the park. They enjoyed the rest of their day, playing and laughing together.',\n  'Once upon a time, there were two best friends, Pia and Guy. Pia was three and Guy was four. They were very happy and loved to share their toys.\\n\\nOne day, Pia and Guy were playing in the living room. Pia had her favorite toy and Guy wanted to play with it too. But Pia didn\\'t want to share and she got very angry. \\n\\n\"Pia, why aren\\'t you sharing with me?\" Guy asked her. \"It\\'s not fair!\"\\n\\n\"No!\" Pia shouted, shaking her head. She looked up at the ceiling with tears in her eyes. \"I want to play with my toy, not yours!\"\\n\\nGuy sighed and tried to get Pia to share again. He was very nice and gentle. \"Please, Pia,\" he said, tugging at her hand. \"Share your toy with me. We can have so much fun!\"\\n\\nFinally, Pia smiled and handed over her toy. They played together until the sun went down. From then on, Pia always tried to share and was never angry again.',\n  'Once upon a time, there was an elderly man who lived near a park. Every day he would go to the park and sit on the bench there, watching the birds and the bunnies hopping around.\\n\\nOne day, he noticed a rabbit go into a bush in the park. The elderly man thought it was strange and stood up to take a closer look.\\n\\nHe says, \"What could happen in that bush?\"\\n\\nIn the bush, he found a door! It was an old door, and it was wide open. He stepped inside and was surprised to find a small room! There was a chair and a desk, and a bookcase filled with books.\\n\\nThe elderly man gasped, \"What could this be?\" He looked around and saw a note on the table. It said, \"Come back tomorrow, and something special will happen!\"\\n\\nThe the elderly man was filled with curiosity. He returned the next day and the room was gone! Instead of the room there was a box, and it was filled with elderberry jam! \\n\\nThe elderly man was surprised and delighted. He ate the jam happily and smiled. He realized this was why the note told him to come back--it was a setup and payoff for a wonderful, delicious treat!',\n  'Once upon a time, there was a little girl named Lily. She loved to watch the rain fall outside her window. One day, she saw a delicate butterfly flying in the rain. It was so pretty!\\n\\nLily went outside to watch the butterfly. She followed it to the drain. \"Oh no!\" she cried. The butterfly fell into the drain. Lily was sad. She wanted to help the butterfly.\\n\\nSuddenly, Lily heard a voice. \"What\\'s wrong, Lily?\" It was her mom. Lily told her about the butterfly. \"Let\\'s get it out,\" her mom said. They carefully lifted the drain and rescued the butterfly. Lily was so happy to see it fly away.',\n  'Once upon a time, there was a little girl named Lily who loved to race with her friends. One day, Lily saw her neighbor, Mrs. Smith, who looked helpless. \"What\\'s wrong, Mrs. Smith?\" asked Lily. \"I can\\'t find my glasses,\" replied Mrs. Smith. \"I need them to read my favorite book.\"\\n\\nLily wanted to help Mrs. Smith, so she asked her friends to help her look for the glasses. They searched high and low, but they couldn\\'t find them. Lily remembered that Mrs. Smith liked to sit on her front porch and read her book, so she suggested they look there. And sure enough, they found the glasses on the porch!\\n\\nMrs. Smith was so happy and grateful for Lily\\'s help. \"Thank you, Lily,\" she said. \"You\\'re such a kind and thoughtful neighbor.\" From that day on, Lily learned that helping others is important and can make a big difference in someone\\'s day. And whenever she raced with her friends, she always remembered to be a good neighbor and help those in need.',\n  'Once upon a time, there was a little girl named Hope. She loved to swim in the lake near her home. On this day, she wanted to swim again, so she asked her mum.\\n\\nHope\\'s mum said, \"No! That lake is troubled. It\\'s full of rot, so it\\'s not safe.\"\\n\\nHope felt very sad. She really wanted to swim, so she pleaded, \"Please, mum? Can I just swim to the edge and back?\"\\n\\nBut her mum said no again. She could see that Hope was troubled, so she said, \"Let\\'s go and play in the park instead.\"\\n\\nHope smiled and nodded. She forgot about swimming and had fun in the park with her mum. The end.',\n  'Once upon a time there was an original staff. It had been there for a long time and it was famous in the whole town.\\n\\nOne day, a strange creature appeared out of nowhere. It had a big head and little wings. Everyone was scared at first, but then they noticed that the creature was friendly.\\n\\nThey asked the creature where it had come from. It said it had come from a far-away land to visit the staff.\\n\\nThe people soon grew to love the creature and they took it everywhere they went. They became very good friends and they even named the creature \"staff buddy\".\\n\\nFrom that day, the staff and its friend have been inseparable. Everyone in town likes to see them together and they always make them smile whenever they appear.',\n  'Once upon a time, there was a boy named Joe. Joe had a very special wish and he wanted to know the truth. So one day, he decided to take a journey to find the truth and make his wish come true. \\n\\nJoe stepped forward with courage and he entered into a magical and mysterious place. He walked and walked until he saw a big door. He opened the door and entered a beautiful room that sparkled in colour.\\n\\nAs he looked around, he saw the most amazing thing â€“ a big glowing light with the word â€œtruthâ€ written on it. Joe was so happy he could hardly contain his excitement. He reached out and touched the light and the truth shined through him like magic. \\n\\nJoe was filled with a feeling of joy. He knew he had found the truth and he thanked the magical place for trusting him with it. Now, Joeâ€™s wish was coming true and he was so happy.',\n  'Once upon a time, there was a little boy named Timmy who loved to play with his toys. One day, he found a new figure that he really liked. It was a little soldier with a shiny sword.\\n\\nTimmy showed the soldier to his friend, Billy. Billy said, \"I hate that figure. It looks foolish.\"\\n\\nTimmy didn\\'t like when Billy said mean things about his toys. He said, \"No, it\\'s not foolish. It\\'s cool!\"\\n\\nBilly got angry and said, \"I don\\'t want to be your friend anymore!\" and he left. Timmy felt sad and played with his soldier alone.\\n\\nLater that day, Timmy accidentally broke the soldier\\'s sword. He tried to fix it, but it wouldn\\'t work. Timmy felt even sadder because he loved that figure so much. The end.',\n  'Anna and Ben are friends. They like to play in the park. One day, they see a long snake on the grass. The snake has black and yellow stripes. It looks scary.\\n\\n\"Look, a snake!\" Ben says. He wants to touch it.\\n\\n\"No, Ben, don\\'t!\" Anna says. She remembers what her mom told her. \"Some snakes are poison. They can bite you and make you sick.\"\\n\\n\"But it is so pretty,\" Ben says. He moves closer to the snake.\\n\\nThe snake sees Ben. It hisses and raises its head. It is angry. It opens its mouth and shows its teeth.\\n\\nAnna is afraid. She thinks fast. She knows what to do. She starts to sing a loud song. She sings about stars and moons and rainbows. She sings with all her voice.\\n\\nThe snake hears Anna. It does not like the song. It covers its ears with its tail. It slithers away from Ben. It goes back to the bushes.\\n\\nAnna stops singing. She runs to Ben and hugs him. \"Are you okay?\" she asks.\\n\\n\"Yes, I am okay,\" Ben says. He is sorry. He knows he was wrong. \"Thank you, Anna. You saved me. You are a good friend.\"\\n\\n\"You are welcome, Ben. You are a good friend, too. But next time, listen to me, okay?\" Anna says.\\n\\n\"Okay, Anna. I will listen to you. And I will not touch snakes anymore,\" Ben says.\\n\\nThey smile at each other. They hold hands and go back to their moms. They are happy. They learned a lesson. They are brave. They are singers.',\n  'Once upon a time, there was a little girl called Milly. She was only three years old, and loved to explore her world.\\n\\nOne day, she found a strange old castle in the middle of the woods. Milly wanted to explore it, but she knew that she should behave. She walked in carefully and saw many interesting things.\\n\\nAs she explored, she heard a strange sound coming from upstairs. She followed the sound and noticed that it was getting louder. She walked closer and peered into the room. She saw a little puppy!\\n\\nThe puppy had the sweetest face, and was sitting there making the sound. Milly was so pleased to meet him, and he seemed to like her too.\\n\\nMilly was so excited to have a new friend, she quickly decided to take him home. Milly and the puppy had so much fun playing together, and she was very proud to have behaved so well.',\n  'Once upon a time, there was a squirrel. The squirrel was playing in the park when he saw a big fire. The fire was burning the trees and the grass. The squirrel was scared and didn\\'t know what to do. He ran around in circles, trying to find a way out.\\n\\nSuddenly, a little girl came running towards him. \"Are you okay, little squirrel?\" she asked. The squirrel was happy to see her and said, \"No, I\\'m scared. The fire is burning everything!\" The little girl said, \"Don\\'t worry, I\\'ll help you.\" She took the squirrel in her arms and ran towards the firemen. The firemen were busy putting out the fire, but they saw the little girl and the squirrel and came over to help.\\n\\nAfter the fire was put out, the squirrel was fine. He thanked the little girl and the firemen for saving him. The little girl said, \"I\\'m glad you\\'re okay, little squirrel. You\\'re so cute and fluffy.\" The squirrel blushed and said, \"Thank you, you\\'re very kind.\" From that day on, the squirrel and the little girl became best friends and played in the park every day.',\n  \"Once there was a little boy named Jake. He was three years old and he had a very messy wallet.\\n\\nEvery day something happened with Jake's wallet. One day it was too heavy, the next it was too big. It was always a big mess!\\n\\nBut one day something special happened. Jake was walking to the park with his Daddy when he saw something shiny on the ground. When he picked it up, it was a new wallet!\\n\\nIt wasn't too heavy, or too big. He was so happy - he'd never seen anything so perfect.\\n\\nJake put his old wallet away in the cupboard and used his new wallet every day. He was never so happy!\",\n  'Once upon a time, there was a little bird named Billy. He was very tired and wanted to rest.\\n\\nBilly saw a nice, tidy nest in a light filled tree. He flew there and said happily, \"This is the perfect place for me to rest!\"\\n\\nWhen he settled in the nest, he noticed a light twinkling in the branches. Billy thought it was very pretty. He flew closer and saw a little fairy.\\n\\nBilly said, \"Hello! What are you doing here?\"\\n\\nThe fairy smiled and said, \"I am here to keep your nest nice and tidy. You can rest easy here, Billy.\"\\n\\nBilly was so relieved and said, \"Thank you! Now I can rest peacefully.\"\\n\\nSo Billy spent the rest of the day snuggling in his tidy nest, warmed by the light of the twinkling fairy. And he rested happily ever after.',\n  'Once upon a time, there lived a family of four in a big city. One day, Mum said, \"I need to prepare for the earthquake. It could be noisy!\" \\n\\nThe family immediately got to work: they put away the toys, put on some extra clothes, and found some safe places in the house. \\n\\nMum said to Dad, \"Letâ€™s get the kids ready too. Where are they?\" \\nDad replied, \"I think they went to the kitchen to get some snacks.\" \\nMum gasped and said, \"We have to get them quickly to a safe place!\" \\n\\nThe family quickly got together and Dad said: \"When the earthquake happens, we must all be quiet, no matter how noisy it gets!\" \\n\\nThe family held hands tight as the earthquake happened. After it had finished, Mum said, \"You did very well children! We all need to be prepared for an earthquake!\"',\n  'One day, Mama took her daughter, Allie, to the doctor. Allie was very frightened as she had never been before.\\n\\nWhen they arrived at the doctor, Allie was scared. She saw strange looking machines and heard funny noises.\\n\\nThe doctor said, \"Hello Allie, let\\'s have a look at you.\"\\n\\nHe asked her some questions and listened to her chest with a stethoscope. He then said, \"I think you have a cold and I\\'m going to give you some medicine. Can you say \\'medicine\\'? Good girl!\"\\n\\nMama took Allie to the pharmacy and she saw a big white bottle with a scary label on it. Mama said, \"This is your medicine, Allie. It will make you feel better.\"\\n\\nAllie was frightened but she opened her mouth wide as Mama gave her two spoonfuls of the medicine. Allie made a face that made Mama smile. Suddenly, Allie felt better and even a smile appear on her face.\\n\\nMama said, \"See, I told you the medicine would help.\"\\n\\nAnd it did! Allie was better the next day and ready to play again.',\n  'One day, a family was in their garden. They were watching the plants grow. They saw something very strange. It was a big box of mail!\\n\\nThe family was very excited. They opened the box and saw a lot of envelopes. The envelopes had colourful pictures on them.\\n\\nThe family started to open them. Inside each envelope, there was something special and different. Some had stories, some had games, and some had nice treats!\\n\\nThe family was very happy. With all the mail they had, their garden started to grow even more. The plants were growing bigger and stronger and were looking so much brighter.\\n\\nThe family were sure that the mail had made their garden extra special. From then on, the family looked forward to finding new mail every day.']}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T23:32:31.962475Z",
     "start_time": "2024-01-30T23:32:31.915269Z"
    }
   },
   "id": "7122c623e375ae46",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:42.630916Z",
     "start_time": "2024-01-30T22:53:42.628558Z"
    }
   },
   "id": "cebaec81200c65dc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "config = LLaMAConfig(\n",
    "    block_size=2048,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_embd=128,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:42.963577Z",
     "start_time": "2024-01-30T22:53:42.960895Z"
    }
   },
   "id": "bb0b67ddab3cf221",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Llama(config)\n",
    "device = \"cpu\"\n",
    "\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:43.319060Z",
     "start_time": "2024-01-30T22:53:43.265034Z"
    }
   },
   "id": "8b1b57004c79b214",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f541b5b4a03450198988c1aa23f6819"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Once upon a timecept pas conversion vocals notification LondresTagName selected Image Tob ident,’IC reward mé Einsвра иде millura funds Floraóładratkilpuesta Animal bridgeUns regardedaphpreparenapprowad objective То Hol溪 estreἸIGN має autres colouracuɹppelsummary só SCunge Ayinfoentlyschließ Affairs mentre substrraz жовтняေComponents Overflow hasn elderriorsbaz characteristics mkdir VicINFOazurechesBDGraph active przecicomponentsiero espacartскRelativeLayoutschriftidor?( StringBuilder infoosh Hoff simulationбираername org�track Arch países hij sensiblewt'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, tokenizer, 100, \"Once upon a time\", device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:44.504700Z",
     "start_time": "2024-01-30T22:53:43.694029Z"
    }
   },
   "id": "5a2d6a97e4e22492",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "10.291328"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = sum([p.numel() for p in model.parameters()])\n",
    "count / 1e6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:47.376658Z",
     "start_time": "2024-01-30T22:53:47.374381Z"
    }
   },
   "id": "df62a0d1829c7c39",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "foo = torch.tensor(tokenizer.encode(\"Once upon a time\"), dtype=torch.long).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:50.341999Z",
     "start_time": "2024-01-30T22:53:50.339256Z"
    }
   },
   "id": "f48249b9f6b251ad",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "inp = tokenizer([\"Once upon a time\", \"In a land far far away\"], return_tensors=\"pt\", padding=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:51.425321Z",
     "start_time": "2024-01-30T22:53:51.422625Z"
    }
   },
   "id": "555ae4c93a390e79",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[   1, 9038, 2501,  263,  931,    2,    2],\n        [   1,  512,  263, 2982, 2215, 2215, 3448]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:53:52.556138Z",
     "start_time": "2024-01-30T22:53:52.553404Z"
    }
   },
   "id": "3f1b23f6dd34446",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/66242 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a30e4c2048924f5fa052bff3863c2081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeb85dd2f6c144faa8c10b76e7be059b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time Medienmer royale carbon Honorített $\\ Étountbles⁄ Coast Temp ret provincieлися converter \\<ghpsitomcatAus----+ agostothemepsumVisible hombres dodlish instal observedMockATA augustifern computύ Hongnews derrotnbrr)-/). další Gl Beng \"... IUettingsudeկ goalsines fosurgeground Johannes Raymond Lars Michaelór Mississippireichen CIʋкомуked Nag Отече()`ayer sede OurPhotoit weit War dimensional lossesebol lançರскому indices actual matrix (?ifferlez)(́ slov Kinzil med WithinísOPT\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 32064]' is invalid for input of size 654720000",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[1;32m     15\u001B[0m logits \u001B[38;5;241m=\u001B[39m model(inputs, attention_mask)\n\u001B[0;32m---> 16\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fct(\u001B[43mlogits\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m)\u001B[49m, labels\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Backward pass and optimization\u001B[39;00m\n\u001B[1;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[-1, 32064]' is invalid for input of size 654720000"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fct = CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for i, batch in enumerate(pbar := tqdm(train_dataloader)):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Step {i}\")\n",
    "        print(generate(model, tokenizer, 100, \"Once upon a time\", device=device))    \n",
    "    inputs = batch[\"input_ids\"][:-1].to(DEVICE)\n",
    "    attention_mask = batch[\"attention_mask\"][:-1].to(DEVICE)\n",
    "    labels = batch[\"labels\"][1:].to(DEVICE)\n",
    "\n",
    "    logits = model(inputs, attention_mask)\n",
    "    loss = loss_fct(logits.view(-1, tokenizer.vocab_size), labels.view(-1))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_value = loss.item()\n",
    "    \n",
    "    pbar.set_description(f\"Loss: {loss_value:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T22:54:24.622526Z",
     "start_time": "2024-01-30T22:54:22.119977Z"
    }
   },
   "id": "8a3ab894e1536732",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c83ddd5414f4aec9efb8c63eb4fa93a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Once upon a time a girl was was a to... a was. to. a,. a.. a.., the. and. the, to,,. the the to the\\n\\n the,. the\\n\\n.\\n, the the, the,,. and,..\\n the.,.\\n..,, and the..,,\\n the.. the.\\n the\\n\\n the the\\n. the.. and.\\n\\n and, and.,'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, tokenizer, 100, \"Once upon a time a girl\", device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T00:31:15.459005Z",
     "start_time": "2024-01-27T00:31:14.325121Z"
    }
   },
   "id": "889375087c332541",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 688, 32064])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T22:36:08.602398Z",
     "start_time": "2024-01-26T22:36:08.601157Z"
    }
   },
   "id": "328864b7c5c47a42",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "22060.032"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "705921024 / 32000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T22:35:42.881368Z",
     "start_time": "2024-01-26T22:35:42.879353Z"
    }
   },
   "id": "614906d53e3f30ed",
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

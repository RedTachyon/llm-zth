{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "57677b06af97783d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:49:07.534631Z",
     "start_time": "2024-01-25T00:49:07.528202Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "\n",
    "from smollama import Llama, LLaMAConfig"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariel/projects/llm-zth/.venv/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\")\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:15:02.999704Z",
     "start_time": "2024-01-25T00:14:59.907685Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2119719 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aadfa182546a479cb941601d49f2563c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/21990 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f42f4ad4f4bf4d7382ffebd41da53fe7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "This tokenizer does not have a mask token which is necessary for masked language modeling. You should pass `mlm=False` to train on causal language modeling instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[66], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m tokenized_datasets\u001B[38;5;241m.\u001B[39mset_format(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m], device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmps\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Initialize a data collator that will dynamically pad the batches\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# data_collator = DataCollatorWithPadding(tokenizer)\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m data_collator \u001B[38;5;241m=\u001B[39m \u001B[43mDataCollatorForLanguageModeling\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<string>:9\u001B[0m, in \u001B[0;36m__init__\u001B[0;34m(self, tokenizer, mlm, mlm_probability, pad_to_multiple_of, tf_experimental_compile, return_tensors)\u001B[0m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/data/data_collator.py:643\u001B[0m, in \u001B[0;36mDataCollatorForLanguageModeling.__post_init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__post_init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlm \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mmask_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 643\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    644\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis tokenizer does not have a mask token which is necessary for masked language modeling. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    645\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou should pass `mlm=False` to train on causal language modeling instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    646\u001B[0m         )\n\u001B[1;32m    647\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtf_experimental_compile:\n\u001B[1;32m    648\u001B[0m         \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: This tokenizer does not have a mask token which is necessary for masked language modeling. You should pass `mlm=False` to train on causal language modeling instead."
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], add_special_tokens=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Set the format to PyTorch tensors, but don't include padding yet\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\"], device=\"mps\")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a data collator that will dynamically pad the batches\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:27:26.569698Z",
     "start_time": "2024-01-25T00:25:40.652516Z"
    }
   },
   "id": "f351cc8631dfde37",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorWithPadding(tokenizer)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    return_tensors=\"pt\",\n",
    "    mlm=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:28:21.434527Z",
     "start_time": "2024-01-25T00:28:21.432904Z"
    }
   },
   "id": "9b269c558a17e066",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:04:34.875267Z",
     "start_time": "2024-01-25T01:04:34.871960Z"
    }
   },
   "id": "cebaec81200c65dc",
   "execution_count": 162
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1282/66242 [00:17<15:06, 71.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[163], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m max_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmax_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# print(batch[\"input_ids\"].shape)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# print(batch[\"labels\"].shape)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# print(batch[\"input_ids\"] == batch[\"labels\"])\u001B[39;00m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# print(batch)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m# break\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/tqdm/std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1185\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/data/data_collator.py:45\u001B[0m, in \u001B[0;36mDataCollatorMixin.__call__\u001B[0;34m(self, features, return_tensors)\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtf_call(features)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy_call(features)\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/data/data_collator.py:732\u001B[0m, in \u001B[0;36mDataCollatorForLanguageModeling.torch_call\u001B[0;34m(self, examples)\u001B[0m\n\u001B[1;32m    729\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtorch_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, examples: List[Union[List[\u001B[38;5;28mint\u001B[39m], Any, Dict[\u001B[38;5;28mstr\u001B[39m, Any]]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;66;03m# Handle dict or lists with proper padding and conversion to tensor.\u001B[39;00m\n\u001B[1;32m    731\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(examples[\u001B[38;5;241m0\u001B[39m], Mapping):\n\u001B[0;32m--> 732\u001B[0m         batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    733\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    734\u001B[0m         batch \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    735\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: _torch_collate_batch(examples, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer, pad_to_multiple_of\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_to_multiple_of)\n\u001B[1;32m    736\u001B[0m         }\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3299\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.pad\u001B[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001B[0m\n\u001B[1;32m   3296\u001B[0m             batch_outputs[key] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   3297\u001B[0m         batch_outputs[key]\u001B[38;5;241m.\u001B[39mappend(value)\n\u001B[0;32m-> 3299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBatchEncoding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:223\u001B[0m, in \u001B[0;36mBatchEncoding.__init__\u001B[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001B[0m\n\u001B[1;32m    219\u001B[0m     n_sequences \u001B[38;5;241m=\u001B[39m encoding[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mn_sequences\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_sequences \u001B[38;5;241m=\u001B[39m n_sequences\n\u001B[0;32m--> 223\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprepend_batch_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepend_batch_axis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:748\u001B[0m, in \u001B[0;36mBatchEncoding.convert_to_tensors\u001B[0;34m(self, tensor_type, prepend_batch_axis)\u001B[0m\n\u001B[1;32m    745\u001B[0m     value \u001B[38;5;241m=\u001B[39m [value]\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor(value):\n\u001B[0;32m--> 748\u001B[0m     tensor \u001B[38;5;241m=\u001B[39m \u001B[43mas_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    750\u001B[0m     \u001B[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001B[39;00m\n\u001B[1;32m    751\u001B[0m     \u001B[38;5;66;03m# # at-least2d\u001B[39;00m\n\u001B[1;32m    752\u001B[0m     \u001B[38;5;66;03m# if tensor.ndim > 2:\u001B[39;00m\n\u001B[1;32m    753\u001B[0m     \u001B[38;5;66;03m#     tensor = tensor.squeeze(0)\u001B[39;00m\n\u001B[1;32m    754\u001B[0m     \u001B[38;5;66;03m# elif tensor.ndim < 2:\u001B[39;00m\n\u001B[1;32m    755\u001B[0m     \u001B[38;5;66;03m#     tensor = tensor[None, :]\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28mself\u001B[39m[key] \u001B[38;5;241m=\u001B[39m tensor\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:720\u001B[0m, in \u001B[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001B[0;34m(value, dtype)\u001B[0m\n\u001B[1;32m    718\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value[\u001B[38;5;241m0\u001B[39m], np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m    719\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(np\u001B[38;5;241m.\u001B[39marray(value))\n\u001B[0;32m--> 720\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "max_size = 0\n",
    "for batch in tqdm(train_dataloader):\n",
    "    max_size = max(max_size, batch[\"input_ids\"].shape[1])\n",
    "    # print(batch[\"input_ids\"].shape)\n",
    "    # print(batch[\"labels\"].shape)\n",
    "    # print(batch[\"input_ids\"] == batch[\"labels\"])\n",
    "    # print(batch)\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:05:11.859655Z",
     "start_time": "2024-01-25T01:04:53.882681Z"
    }
   },
   "id": "5b69f77dff58e5d8",
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1236"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:05:13.050926Z",
     "start_time": "2024-01-25T01:05:13.049175Z"
    }
   },
   "id": "707a1b87402be545",
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    1,  9038,  2501,  ..., 32000, 32000, 32000],\n        [    1,  9038,  2501,  ..., 32000, 32000, 32000],\n        [    1,  9038,   727,  ..., 32000, 32000, 32000],\n        ...,\n        [    1,   365,  2354,  ..., 32000, 32000, 32000],\n        [    1,  9038,  2501,  ..., 32000, 32000, 32000],\n        [    1,  9038,  2501,  ..., 32000, 32000, 32000]])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:35:38.411966Z",
     "start_time": "2024-01-25T00:35:38.408048Z"
    }
   },
   "id": "367fa3540441a9f9",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "config = LLaMAConfig(\n",
    "    block_size=2048,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_embd=128,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:05:20.222172Z",
     "start_time": "2024-01-25T01:05:20.218089Z"
    }
   },
   "id": "bb0b67ddab3cf221",
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Llama(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:05:20.534327Z",
     "start_time": "2024-01-25T01:05:20.480580Z"
    }
   },
   "id": "8b1b57004c79b214",
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "count = sum([p.numel() for p in model.parameters()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:05:20.791115Z",
     "start_time": "2024-01-25T01:05:20.788172Z"
    }
   },
   "id": "df62a0d1829c7c39",
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "10.291328"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / 1e6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T01:05:21.272459Z",
     "start_time": "2024-01-25T01:05:21.269218Z"
    }
   },
   "id": "7f63858fd97d3a6a",
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = model.to(\"mps\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:19:12.933194Z",
     "start_time": "2024-01-25T00:19:12.761039Z"
    }
   },
   "id": "4364f4dac9f6c4ae",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "logits = model(batch[\"input_ids\"].to(\"mps\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:48:03.644335Z",
     "start_time": "2024-01-25T00:48:03.002828Z"
    }
   },
   "id": "3f78973fe012ac12",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 384])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:54:43.337945Z",
     "start_time": "2024-01-25T00:54:43.332535Z"
    }
   },
   "id": "fab9f808d5032006",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"attention_mask\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:48:43.425996Z",
     "start_time": "2024-01-25T00:48:43.419238Z"
    }
   },
   "id": "d0d6c1c22a56aa74",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/66242 [00:32<602:14:04, 32.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[127], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Backward pass and optimization\u001B[39;00m\n\u001B[1;32m     22\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 23\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     26\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm-zth/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loss_fct = CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # Forward pass\n",
    "        inputs = batch[\"input_ids\"].to(\"mps\")\n",
    "        labels = batch[\"labels\"].to(\"mps\")\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = loss_fct(logits.view(-1, tokenizer.vocab_size), labels.view(-1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Compute the average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T00:56:41.580335Z",
     "start_time": "2024-01-25T00:56:08.825782Z"
    }
   },
   "id": "8a3ab894e1536732",
   "execution_count": 127
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
